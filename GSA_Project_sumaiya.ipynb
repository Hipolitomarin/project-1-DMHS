{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2609b654-4b52-4536-9b15-f75887254519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e088dc5c-860e-4e7e-a15e-1e489e757eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('GSAF5.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab1c16-703a-4901-bf65-45c4dd99071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e5b13-5ef1-4343-aa5a-14b287cdc40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Type\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b210af4-b94b-4932-823a-0258188d9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Injury\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4063a9-88f1-45c4-bbc4-597614dc870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Time\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928408b6-2625-4d4f-befc-3950a129b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"].isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab2a309-b05f-427e-ad71-776b6bc7e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_time(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "\n",
    "    value = str(value).strip().lower()\n",
    "\n",
    "    # Remove useless or unclear values\n",
    "    if value in [\"?\", \"am\", \"pm\", \"unknown\", \"not stated\", \"n/a\", \"na\"]:\n",
    "        return None\n",
    "\n",
    "    # Clean formats like \"after 1200hr\", \"11.30hr\", \"15.5\", etc.\n",
    "    match = re.search(r'(\\d{1,2})[h:.]?(\\d{2})?', value)\n",
    "\n",
    "    if match:\n",
    "        hour = match.group(1)\n",
    "        minute = match.group(2) if match.group(2) else \"00\"\n",
    "        return f\"{hour.zfill(2)}:{minute.zfill(2)}\"\n",
    "\n",
    "    # Keep known phrases like \"Morning\", \"Afternoon\", etc.\n",
    "    return value.title()\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3fb6d0-b495-4414-bbd5-8567cb2ac12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def precise_time_to_day_part(value):\n",
    "    if value is None:\n",
    "        return None  # Keep missing as None\n",
    "\n",
    "    # Known descriptive phrases to keep untouched\n",
    "    descriptive_parts = [\n",
    "        \"Early Morning\", \"Morning\", \"Midday\", \"Early Afternoon\",\n",
    "        \"Late Afternoon\", \"Afternoon\", \"Evening\", \"Dusk\",\n",
    "        \"Night\", \"Late Night\"\n",
    "    ]\n",
    "    \n",
    "    if isinstance(value, str) and value.title() in descriptive_parts:\n",
    "        return value.title()\n",
    "\n",
    "    try:\n",
    "        # Try parsing standard time like \"14:30\"\n",
    "        time = datetime.strptime(value, \"%H:%M\").time()\n",
    "        hour = time.hour\n",
    "        minute = time.minute\n",
    "\n",
    "        if 5 <= hour < 8:\n",
    "            return \"Early Morning\"\n",
    "        elif 8 <= hour < 12:\n",
    "            return \"Morning\"\n",
    "        elif hour == 12 and minute == 0:\n",
    "            return \"Midday\"\n",
    "        elif 12 <= hour < 15:\n",
    "            return \"Early Afternoon\"\n",
    "        elif 15 <= hour < 17:\n",
    "            return \"Late Afternoon\"\n",
    "        elif 17 <= hour < 19:\n",
    "            return \"Evening\"\n",
    "        elif 19 <= hour < 20:\n",
    "            return \"Dusk\"\n",
    "        elif 20 <= hour < 24:\n",
    "            return \"Night\"\n",
    "        else:  # 00:00 to before 5:00\n",
    "            return \"Late Night\"\n",
    "    except:\n",
    "        return None  # Unrecognized values go to None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bbb2c4-db47-4ede-b4dc-d60533f0131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cleaned_Time'] = df['Time'].apply(clean_time)\n",
    "df['Day_Part'] = df['Cleaned_Time'].apply(precise_time_to_day_part)\n",
    "print(df['Day_Part'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab64f08-1347-452c-be50-612b924ce354",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cleaned_Time'].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082ff2da-df19-4a0e-9633-9ff01144a18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Day_Part'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750145cb-cfd0-4967-9d9f-d42513b71c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"].value_counts().tail(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d908ec7-bb8c-4372-837d-6b4ce1a5f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_date(date):\n",
    "    date = str(date)\n",
    "    \n",
    "    # Remove known unwanted words\n",
    "    cleaned_date = re.sub(r'\\b(Reported|Early|Before|No date|No Date)\\b', '', date, flags=re.IGNORECASE)\n",
    "    cleaned_date = re.sub(r'[^0-9a-zA-Z\\-/ :]', '', cleaned_date).strip()\n",
    "\n",
    "    # Try known formats first\n",
    "    for fmt in (\"%d-%b-%Y\", \"%d %b-%Y\", \"%Y-%m-%d %H:%M:%S\", \"%d-%m-%Y\", \"%Y-%m-%d\"):\n",
    "        try:\n",
    "            return pd.to_datetime(cleaned_date, format=fmt, errors='raise')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # Fall back to automatic parsing (dayfirst off for ISO formats)\n",
    "    return pd.to_datetime(cleaned_date, errors='coerce', dayfirst=False)\n",
    "df['Cleaned_Date'] = df['Date'].apply(clean_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3023c-199b-46ef-ab7f-414c94509873",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cleaned_Date'].tail(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d69a4fa-6e3f-41fc-9835-93cfe950c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(date):\n",
    "    if pd.isna(date):\n",
    "        return \"No Date\"\n",
    "    \n",
    "    month = date.month\n",
    "    if month in [3, 4, 5]:\n",
    "        return \"Spring\"\n",
    "    elif month in [6, 7, 8]:\n",
    "        return \"Summer\"\n",
    "    elif month in [9, 10, 11]:\n",
    "        return \"Autumn\"\n",
    "    elif month in [12, 1, 2]:\n",
    "        return \"Winter\"\n",
    "    \n",
    "    return \"No Date\"\n",
    "\n",
    "# Apply season mapping\n",
    "df['Season'] = df['Cleaned_Date'].apply(get_season)\n",
    "\n",
    "print(df[['Date', 'Cleaned_Date', 'Season']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afb351f-b3c4-4367-bb66-22be6298b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb1ffa-b371-4a10-87dd-dd4d27bc37fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df[\"Injury\"].value_counts().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957156ce-d953-4929-8dd7-d98d398c9773",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df[\"Injury\"].value_counts()\n",
    "\n",
    "# Filter where count is exactly 1\n",
    "single_occurrences = counts[counts == 1]\n",
    "\n",
    "# Show how many have count = 1\n",
    "print(f\"Number of unique injuries that appear only once: {len(single_occurrences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fda8ea-171c-496b-902f-3b701d770597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Injury_clean\"] = (\n",
    "    df[\"Injury\"]\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r'[^a-z\\s]', '', regex=True)  # Remove non-letter characters\n",
    ")\n",
    "\n",
    "# Quick grouping preview\n",
    "print(df[\"Injury_clean\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef37a1-edec-4485-81ce-dd525c0f428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_injury(text):\n",
    "    if pd.isna(text):\n",
    "        return \"unknown\"\n",
    "    text = text.lower()\n",
    "    if \"fatal\" in text:\n",
    "        return \"fatal\"\n",
    "    elif \"foot\" in text:\n",
    "        return \"foot injury\"\n",
    "    elif \"leg\" in text:\n",
    "        return \"leg injury\"\n",
    "    elif \"hand\" in text:\n",
    "        return \"hand injury\"\n",
    "    elif \"no injury\" in text:\n",
    "        return \"no injury\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "df[\"Injury_grouped\"] = df[\"Injury\"].apply(simplify_injury)\n",
    "print(df[\"Injury_grouped\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31615558-3fbe-4c81-9bc1-f17158c903b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Injury_grouped\"].value_counts().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dc19bd-7170-4c23-a4b5-e02c86167c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                 # HIPOLITO PART\n",
    "\n",
    "#CLEAN THE FATAL COlUMN:\n",
    "\n",
    "\n",
    "# Check the unique values in the column 'Fatal Y/N':\n",
    "print(df['Fatal Y/N'].dropna().apply(lambda x: repr(x)).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba6de5-8351-4d8d-9be3-5dd461c85607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to string and eliminate spaces\n",
    "df['Fatal Y/N'] = df['Fatal Y/N'].astype(str).str.strip().str.upper()\n",
    "#Check for valid values\n",
    "valid_values = {'Y': 'Y', 'N': 'N'}\n",
    "#Put all the good values the rest will be NaN\n",
    "df['Fatal Y/N'] = df['Fatal Y/N'].map(valid_values)\n",
    "#Result\n",
    "print(df['Fatal Y/N'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7feea-d90c-4c39-9747-bf11210e3589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of values (Y, N)\n",
    "print(df['Fatal Y/N'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f754035-34b2-456c-a02f-e26d978d036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values in the column 'Country'\n",
    "print(df['Country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb10faae-65a7-47c3-932e-041bdcd5323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All in mayus and eliminate spaces\n",
    "df['Country'] = df['Country'].str.strip().str.upper()\n",
    "print(df['Country'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50f760-c50f-4b3e-bee7-93224179762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING DATA OF COUNTRIES\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "country_corrections = {\n",
    "    # Correccions Ortografics\n",
    "    'COLUMBIA': 'COLOMBIA',\n",
    "    'TRINIDAD & TOBAGO': 'TRINIDAD AND TOBAGO',\n",
    "    'MALDIVE ISLANDS': 'MALDIVES',\n",
    "    'UNITED ARAB EMIRATES (UAE)': 'UNITED ARAB EMIRATES',\n",
    "    'ST. MARTIN': 'ST MARTIN',\n",
    "    'ST. MAARTIN': 'ST MARTIN',\n",
    "    'TRINIDAD': 'TRINIDAD AND TOBAGO',\n",
    "\n",
    "    # Agrupations\n",
    "    'ENGLAND': 'UK',\n",
    "    'SCOTLAND': 'UK',\n",
    "    'UNITED KINGDOM': 'UK',\n",
    "    'BRITISH ISLES': 'UK',\n",
    "    'BRITISH WEST INDIES': 'UK',\n",
    "    'BRITISH VIRGIN ISLANDS': 'UK',\n",
    "\n",
    "    # Ocean y region not usefull\n",
    "    'PACIFIC OCEAN': 'OTHER',\n",
    "    'ATLANTIC OCEAN': 'OTHER',\n",
    "    'INDIAN OCEAN': 'OTHER',\n",
    "    'SOUTH PACIFIC OCEAN': 'OTHER',\n",
    "    'CARIBBEAN SEA': 'OTHER',\n",
    "    'OCEAN': 'OTHER',\n",
    "    'GULF OF ADEN': 'OTHER',\n",
    "    'MID-PACIFC OCEAN': 'OTHER',\n",
    "    'NORTH ATLANTIC OCEAN': 'OTHER',\n",
    "    'RED SEA': 'OTHER',\n",
    "    'RED SEA / INDIAN OCEAN': 'OTHER',\n",
    "    'NORTH PACIFIC OCEAN': 'OTHER',\n",
    "    'CENTRAL PACIFIC': 'OTHER',\n",
    "\n",
    "    # Some other mistakes → agrupar\n",
    "    'DIEGO GARCIA': 'OTHER',\n",
    "    'JOHNSTON ISLAND': 'OTHER',\n",
    "    'ADMIRALTY ISLANDS': 'OTHER',\n",
    "    'MID ATLANTIC OCEAN': 'OTHER',\n",
    "    'UNKNOWN': 'OTHER',\n",
    "    'AFRICA': 'OTHER',\n",
    "    'ASIA?': 'OTHER',\n",
    "    'SUDAN?': 'SUDAN',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a757f459-86a8-4408-99f8-ac67f415af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the country correction on or columns\n",
    "\n",
    "def clean_column_country(df, column='Country'):\n",
    "    # All mayus\n",
    "    df[column] = df[column].str.strip().str.upper()\n",
    "    #use the country_corrections to filter the column\n",
    "    df[column] = df[column].replace(country_corrections)\n",
    "    return df\n",
    "\n",
    "df = clean_column_country(df, column='Country')\n",
    "\n",
    "print(sorted(df['Country'].dropna().unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71be513e-41b4-4a43-94ae-a9e329b79716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 countries with more sharks attacts:\n",
    "top_10_paises = df['Country'].value_counts().head(10)\n",
    "print(top_10_paises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c6991-9b4c-401a-bcae-3e3f0831cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b5a96-3de0-4ac5-9ec1-944834575dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4bc45-69a7-4302-81ad-a23e04347029",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8980d-9eff-49b5-8bc6-749e6fe36ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ab9d8-26eb-4f79-8103-d9f279767e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb5a206-2b5d-4d00-9d73-86d2f92bb932",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ce5c7-9a60-42fa-be1f-3475897c6fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c64bdb8-dbaa-4901-a497-7b38927a9913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e1d95-3b84-4f51-8952-2acf76f327b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Location\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0db09d-bec2-4508-bd30-104abf15f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"State\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d325eb-9c95-48dc-a3eb-4789e70556d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418897a-e365-489d-9593-94d139161ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"State\"]].all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ac2d20-cfb0-4ae7-80d9-5b5d821f447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Location.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf6a0c7-1a88-4b75-888e-58dea58368b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "df['Location'] = df['Location'].replace({\n",
    "    'Panama Bay 8ºN, 79ºW': 'Panama Bay'\n",
    "}) \n",
    "print(df['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0524462c-dec2-4881-bd6a-921420c1f91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_location(df,column='Location'):\n",
    "    df[column] = df[column].str.strip().str.upper()\n",
    "    df[column] = df[column].replace(df['Location']).unique\n",
    "    return df\n",
    "\n",
    "df = clean_column_location(df,column='Location')\n",
    "print(sorted(df['Location'].dropna().unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899faaef-511f-4843-8754-b76409bd18fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.State.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40f5182-023c-46f4-8216-dc727a51027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['State'].fillna(method='ffill').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee043760-69a6-4cc0-97f0-b3a1b248927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "State = {\n",
    "    'Floria': 'Florida',\n",
    "    'South Carolina ': 'South Carolina',\n",
    "    'North Carolina ': 'North Carolina',\n",
    "    'New  South Wales': 'New South Wales',\n",
    "    'New South ales': 'New South Wales',\n",
    "    'New South Wales ': 'New South Wales',\n",
    "    'Baja ': 'Baja California',\n",
    "    'Westerm Australia': 'Western Australia',\n",
    "    'Maahvah Laamu Atoll': 'Laamu Atoll',\n",
    "    'Grand  Bahama Island': 'Grand Bahama Island',\n",
    "    'Isla De San Andres': 'San Andrés Island',\n",
    "    'Lucayan Lucayan Archipelago': 'Lucayan Archipelago',\n",
    "    'New Providence   Isoad': 'New Providence Island',\n",
    "    'Hurghada, Red Sea Governorate': 'Red Sea Governorate',\n",
    "    'KwaZulu-Natal between Port Edward and Port St Johns': 'KwaZulu-Natal',\n",
    "    'Western  Australia': 'Western Australia',\n",
    "    'Western Cape Province': 'Western Cape',\n",
    "    'Noirth Carolina': 'North Carolina',\n",
    "    'Guerro': 'Guerrero',\n",
    "    'Guerrrero': 'Guerrero',\n",
    "    'Namonuito Atoll': 'Micronesia',\n",
    "    'Grand Baie': 'Mauritius',\n",
    "    'Guantanamo Province': 'Guantánamo Province',\n",
    "    'Unknown, treated at Wick, SCOTLAND': 'Unknown',\n",
    "    'Bahamas': 'The Bahamas',\n",
    "    'BAHAMAS': 'The Bahamas',\n",
    "    'Exumas': 'Exuma Islands',\n",
    "    'Grand Bahama Island': 'Grand Bahama Island',\n",
    "    ' Grand Bahama Island': 'Grand Bahama Island',\n",
    "    'South Santo': 'Espírito Santo',\n",
    "    'Montego Bay': 'Jamaica',\n",
    "    'Grande Terre': 'New Caledonia',\n",
    "    '?': 'Unknown',\n",
    "    'nan': 'Unknown',\n",
    "    'Lucayan Lucayan Archipelago': 'Lucayan Archipelago',\n",
    "    'South Province': 'Unknown',\n",
    "    'KNZ': 'KwaZulu-Natal', \n",
    "    'New South ales': 'New South Wales',\n",
    "    'Noirth Carolina': 'North Carolina',\n",
    "    'KZN':'KwaZulu-Natal', \n",
    "    '40 miles off Grand Bahama Island': 'Unknown', \n",
    "    '740 miles SE of Tarawa Atoll':'Unknown',\n",
    "    '300 miles from Antigua': 'Unknown',\n",
    "    '800 miles from land': 'Unknown',\n",
    "    '600 nm west of the Canary Islands': 'Unknown', \n",
    "    'KwaZulu-Natal between Port Edward and Port St Johns': 'Unknown',\n",
    "    '12 miles off the north coast': 'Unknown',\n",
    "    'New Territories': 'Unknown',\n",
    "    'On the Kowloon penisula, south of Sai Kung': 'Unknown',\n",
    "    'Between DR and Puerto Rico': 'Unknown', \n",
    "    'Between Honiara & Isabel Island': 'Unknown',\n",
    "    \"Ha'api\": 'Unknown', \n",
    "    'South China Sea 200 miles from Hong Kong': 'Unknown',\n",
    "    '200 nm southeast of Manila': 'Unknown', \n",
    "    \"250 miles southwest of O'ahu, Hawaii\": 'Unknown',\n",
    "    'Near Bougainville (North Solomons)': 'Unknown', \n",
    "    'Off the Coromandel Peninsula, North Island': 'Unknown',\n",
    "    '10ºS, 142ºE': 'Unknown', \n",
    "    '165  miles from Bermuda': 'Unknown',\n",
    "    '25 km off the coast of Iran & 483km from mouth of Persian Gulf': 'Unknown',\n",
    "    '19S, 178?E': 'Unknown', \n",
    "    '9.35N 79.35W': 'Unknown', \n",
    "    'Enroute from Suez to Aden (Yemen)': 'Unknown',\n",
    "    '180 miles southeast of Okinawa': 'Unknown', \n",
    "    'In the English Channel ': 'Unknown',\n",
    "    'Unknown, treated at Wick, SCOTLAND': 'Unknown',\n",
    "    '33N, 68W': 'Unknown', \n",
    "    'Madang (WO)': 'Unknown', \n",
    "    'Between Timor & Darwin, Australia': 'Unknown',\n",
    "    '400 miles southeast of Sri Lanka': 'Unknown',\n",
    "    'In the Gulf Stream ': 'Unknown',\n",
    "    'Between England & South Africa': 'Unknown', \n",
    "    'Mindanao': 'Unknown',\n",
    "    'Between Hawaii & Wake Island': 'Unknown', \n",
    "    '1,000 miles east of Hawaii': 'Unknown', \n",
    "    'Central Province': 'Unknown',\n",
    "    '1000 miles west of Hawaii': 'Unknown', \n",
    "    '18S / 50E': 'Unknown',\n",
    "    '330 to 350 miles east of Wake Island': 'Unknown',\n",
    "    'Between Kwajalein Atoll & Johnston Island': 'Unknown', \n",
    "    'In transit between Tinian and Leyte': 'Unknown',\n",
    "    '300 miles east of Luzon': 'Unknown',\n",
    "    'Bernardino Strait near Gulf of Leyte': 'Unknown',\n",
    "    'Off Samar Island in the Gulf of Leyte': 'Unknown',\n",
    "    'Lake Nicaragua (fresh water)': 'Unknown', \n",
    "    'Near the Fiji Islands': 'Unknown', \n",
    "    '40 miles south of Naples ': 'Unknown',\n",
    "    'Northwest of Papua New Guinea': 'Unknown', \n",
    "    'Between Hawaii and U.S.A.': 'Unknown',\n",
    "    'Off South American coast': 'Unknown',\n",
    "    '04.05N-13.23W': 'Unknown', \n",
    "    '300 miles east of St. Thomas (Virgin Islands)': 'Unknown',\n",
    "    'West of Ceylon (Sri  Lanka)': 'Unknown', \n",
    "    'Off Libya': 'Unknown',  \n",
    "    'North of Pernambuco, Brazil': 'Unknown', \n",
    "    'In Convoy OB 274': 'Unknown', \n",
    "    '2 to 3 miles off Taboguilla Island, Pacific Ocean': 'Unknown', \n",
    "    '150 miles offshore': 'Unknown', \n",
    "    '60 miles north of San Domingo in the West Indies': 'Unknown', \n",
    "    '30 nm from Singapore': 'Unknown',\n",
    "    'Somewhere between Philadelphia and Hiogo, Japan': 'Unknown', \n",
    "    'Between Hastings & Fairlight, Sussex': 'Unknown', \n",
    "    'Off the coast of South America': 'Unknown', \n",
    "    '22ºN, 88ºE': 'Unknown',\n",
    "    '300 miles east of Mauritius': 'Unknown',\n",
    "    'Between Australia & USA': 'Unknown', \n",
    "    \"35º39 : 165º8'\": 'Unknown', \n",
    "    'Between New Ireland & New Britain': 'Unknown'\n",
    "}  \n",
    "\n",
    "\n",
    "df['state_clean'] = df['State'].str.strip()\n",
    "\n",
    "# Apply mapping\n",
    "df['state_standardized'] = df['state_clean'].replace('State')\n",
    "\n",
    "# Optional: Replace all nulls or ambiguous with 'Unknown'\n",
    "df['state_standardized'] = df['state_standardized'].fillna('Unknown')\n",
    "\n",
    "# Check unique cleaned states\n",
    "cleaned_unique_state = df['state_standardized'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a56bfd-b726-41c2-a413-7d57c6429091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_state(df, column='State'):\n",
    "    df[column] = df[column].str.strip().str.upper()\n",
    "    df[column] = df[column].replace('state')\n",
    "    return df\n",
    "\n",
    "df = clean_column_state(df,column='State')\n",
    "print(sorted(df['State'].dropna().unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea337e6b-8d64-4a7a-ac94-f4df2e44d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 State with more shark attack\n",
    "top_10_state = df['State'].value_counts().head(10)\n",
    "print(top_10_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc2714-d515-46b2-8ad2-33f96facb1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feea4d6-45a7-4437-9646-003de894266b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fc1786-86d8-49c6-bd06-136669b5d366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08519edd-d850-481a-b598-28332cf8214e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba9db9-67f6-4cee-9d13-a112630ebae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a7cddd-fcb9-43a7-b2bd-b8c668f6a660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
