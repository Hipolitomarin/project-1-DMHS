{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2609b654-4b52-4536-9b15-f75887254519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('/Users/souadmouajel/Desktop/Ironhack/lab-sessions/week-2/project-week2/GSAF5.xls')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab1c16-703a-4901-bf65-45c4dd99071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4063a9-88f1-45c4-bbc4-597614dc870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenges of Time feature: \n",
    "# 1 . alot of missing values\n",
    "print(f\"sum_of_missing_values: {df[\"Time\"].isnull().sum()}\")\n",
    "print()\n",
    "missing_percent = df[\"Time\"].isnull().sum() / len(df) * 100\n",
    "print(f\"Percentage of missing values: {missing_percent:.2f}%\")\n",
    "print ()\n",
    "print(f\"Huge format variations: see the last 50 value counts\") \n",
    "df[\"Time\"].value_counts().tail(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab2a309-b05f-427e-ad71-776b6bc7e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two steps clean and transform the Time featuers\n",
    "# First, define a function to replace strange formates with valid ones using reg method (valid method can be strin like Late Afternoon, keep the valid ones \n",
    "# but null values have'nt replaced because they are a lot so we avoided the bias\"\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_time(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "\n",
    "    value = str(value).strip().lower()\n",
    "\n",
    "    # Remove useless or unclear values\n",
    "    if value in [\"?\", \"am\", \"pm\", \"unknown\", \"not stated\", \"n/a\", \"na\"]:\n",
    "        return None\n",
    "\n",
    "    # Clean formats like \"after 1200hr\", \"11.30hr\", \"15.5\", etc.\n",
    "    match = re.search(r'(\\d{1,2})[h:.]?(\\d{2})?', value)\n",
    "\n",
    "    if match:\n",
    "        hour = match.group(1)\n",
    "        minute = match.group(2) if match.group(2) else \"00\"\n",
    "        return f\"{hour.zfill(2)}:{minute.zfill(2)}\"\n",
    "\n",
    "    # Keep known phrases like \"Morning\", \"Afternoon\", etc.\n",
    "    return value.title()\n",
    "from datetime import datetime\n",
    "\n",
    "# clean time results:\n",
    "df['Cleaned_Time'] = df['Time'].apply(clean_time)\n",
    "print(df['Cleaned_Time'].tail(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3fb6d0-b495-4414-bbd5-8567cb2ac12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second is to transform the inputs of so the datetime. \n",
    "# New function will be developed then it will applied on Time but the result will be saved on new feature called later Day_Part \n",
    "from datetime import datetime\n",
    "\n",
    "def precise_time_to_day_part(value):\n",
    "    if value is None:\n",
    "        return None  # Keep missing as None\n",
    "\n",
    "    # Known descriptive phrases to keep untouched\n",
    "    descriptive_parts = [\n",
    "        \"Early Morning\", \"Morning\", \"Midday\", \"Early Afternoon\",\n",
    "        \"Late Afternoon\", \"Afternoon\", \"Evening\", \"Dusk\",\n",
    "        \"Night\", \"Late Night\"\n",
    "    ]\n",
    "    \n",
    "    if isinstance(value, str) and value.title() in descriptive_parts:\n",
    "        return value.title()\n",
    "\n",
    "    try:\n",
    "        # Try parsing standard time like \"14:30\"\n",
    "        time = datetime.strptime(value, \"%H:%M\").time()\n",
    "        hour = time.hour\n",
    "        minute = time.minute\n",
    "\n",
    "        if 5 <= hour < 8:\n",
    "            return \"Early Morning\"\n",
    "        elif 8 <= hour < 12:\n",
    "            return \"Morning\"\n",
    "        elif hour == 12 and minute == 0:\n",
    "            return \"Midday\"\n",
    "        elif 12 <= hour < 15:\n",
    "            return \"Early Afternoon\"\n",
    "        elif 15 <= hour < 17:\n",
    "            return \"Late Afternoon\"\n",
    "        elif 17 <= hour < 19:\n",
    "            return \"Evening\"\n",
    "        elif 19 <= hour < 20:\n",
    "            return \"Dusk\"\n",
    "        elif 20 <= hour < 24:\n",
    "            return \"Night\"\n",
    "        else:  # 00:00 to before 5:00\n",
    "            return \"Late Night\"\n",
    "    except:\n",
    "        return None  # Unrecognized values go to None\n",
    "df['Cleaned_Time'] = df['Time'].apply(clean_time)\n",
    "df['Day_Part'] = df['Cleaned_Time'].apply(precise_time_to_day_part)\n",
    "print(df['Day_Part'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d676f522-223b-4fb2-8ee9-a33e46cfb48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99712aa7-7d07-48c7-9470-c89aadf43f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenges of Date feature: \n",
    "# 1 . There are no of missing values but we have to transform the values\n",
    "print(f\"sum_of_missing_values: {df[\"Date\"].isnull().sum()}\")\n",
    "print()\n",
    "missing_percent = df[\"Date\"].isnull().sum() / len(df) * 100\n",
    "print(f\"Percentage of missing values: {missing_percent:.2f}%\")\n",
    "print ()\n",
    "print(f\"Huge format variations: see the last 50 value counts\") \n",
    "df[\"Date\"].value_counts().tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3007238e-6547-4046-955d-26aef080406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to transform the Date column first we have to make sure \"Date\" column is in datetime format,\n",
    "# So Text like \"Unknown\"; Dates missing month or day (e.g., \"2023\" or \"March 2023\"), Any other invalid format\n",
    "df['Cleaned_Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "# Second we have to define the lables, we choose range date lables rather than season ones becuase the seasons can be different accoring to the country\n",
    "def get_date_range_label(date):\n",
    "    if pd.isna(date):\n",
    "        return \"No Date\"\n",
    "    \n",
    "    day_of_year = date.timetuple().tm_yday  # Day number within the year\n",
    "\n",
    "    # Margins based on the year of the date\n",
    "    spring_start = datetime(date.year, 3, 21).timetuple().tm_yday\n",
    "    summer_start = datetime(date.year, 6, 21).timetuple().tm_yday\n",
    "    autumn_start = datetime(date.year, 9, 21).timetuple().tm_yday\n",
    "    winter_start = datetime(date.year, 12, 21).timetuple().tm_yday\n",
    "\n",
    "    if spring_start <= day_of_year < summer_start:\n",
    "        return \"21-03 to 21-06\"\n",
    "    elif summer_start <= day_of_year < autumn_start:\n",
    "        return \"21-06 to 21-09\"\n",
    "    elif autumn_start <= day_of_year < winter_start:\n",
    "        return \"21-09 to 21-12\"\n",
    "    else:\n",
    "        return \"21-12 to 21-03\"\n",
    "\n",
    "# Apply\n",
    "df['Date_Range_Label'] = df['Cleaned_Date'].apply(get_date_range_label)\n",
    "\n",
    "print(df[['Date', 'Cleaned_Date', 'Date_Range_Label']].head(5))\n",
    "print ()\n",
    "date_range_missing_values = df['Date_Range_Label'].value_counts().head(10)\n",
    "print (f\"Note: that we have now in Date_Range_Label some missing values {date_range_missing_values} called No Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb1ffa-b371-4a10-87dd-dd4d27bc37fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenges of Injury feature: \n",
    "# 1 . There are few of missing values but variance is very high\n",
    "# Challenges of Injury feature:\n",
    "print(f\"Sum of missing values: {df['Injury'].isnull().sum()}\\n\")\n",
    "\n",
    "missing_percent = df[\"Injury\"].isnull().sum() / len(df) * 100\n",
    "print(f\"Percentage of missing values: {missing_percent:.2f}%\\n\")\n",
    "\n",
    "print(\"Huge format variations: see the last 50 value counts\")\n",
    "counts = df[\"Injury\"].value_counts()\n",
    "print(counts.tail(50))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Filter where count is exactly 1\n",
    "single_occurrences = counts[counts == 1]\n",
    "\n",
    "# Show how many have count = 1\n",
    "print(f\"Number of unique injuries that appear only once: {len(single_occurrences)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fda8ea-171c-496b-902f-3b701d770597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to clean column Injury we went in two steps first:\n",
    "# Purpose:\n",
    "# Clean the \"Injury\" column text so that entries with the same injury but different cases, extra spaces, or special characters are standardized.\n",
    "# for example: Lowercase: \"Sprain\" and \"sprain\" should be treated the same.\n",
    "# Also Strip: Removes accidental spaces around text (\" sprain \", \"sprain \").\n",
    "# Replace: Remove anything that is not a lowercase letter or space — this deletes numbers, punctuation, symbols, etc.\n",
    "# For example, \"Sprain#1\" → \"sprain\"\n",
    "# So we difned new column called Injury_clean using reex technic\n",
    "df[\"Injury_clean\"] = (\n",
    "    df[\"Injury\"]\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r'[^a-z\\s]', '', regex=True)  # Remove non-letter characters\n",
    ")\n",
    "\n",
    "# Quick grouping preview\n",
    "print(df[\"Injury_clean\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef37a1-edec-4485-81ce-dd525c0f428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second step we define new function called simplify_injury to recategorize all the the values in 7 categories,\n",
    "# and generated new column called Injury grouped\n",
    "def simplify_injury(text):\n",
    "    if pd.isna(text):\n",
    "        return \"unknown\"\n",
    "    text = text.lower()\n",
    "    if \"fatal\" in text:\n",
    "        return \"fatal\"\n",
    "    elif \"foot\" in text:\n",
    "        return \"foot injury\"\n",
    "    elif \"leg\" in text:\n",
    "        return \"leg injury\"\n",
    "    elif \"hand\" in text:\n",
    "        return \"hand injury\"\n",
    "    elif \"no injury\" in text:\n",
    "        return \"no injury\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "df[\"Injury_grouped\"] = df[\"Injury\"].apply(simplify_injury)\n",
    "print(df[\"Injury_grouped\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31615558-3fbe-4c81-9bc1-f17158c903b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dc19bd-7170-4c23-a4b5-e02c86167c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
